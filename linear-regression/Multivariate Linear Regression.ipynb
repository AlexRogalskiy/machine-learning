{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression with multiple variables is also known as \"multivariate linear regression\". We now introduce notation for equations where we can have any number of input variables.\n",
    "\n",
    "### General Formulation\n",
    "\n",
    "$\\begin{align*}x_j^{(i)} &= \\text{value of feature } j \\text{ in the }i^{th}\\text{ training example} \\newline x^{(i)}& = \\text{the input (features) of the }i^{th}\\text{ training example} \\newline m &= \\text{the number of training examples} \\newline n &= \\text{the number of features} \\end{align*}$\n",
    "\n",
    "The multivariable form of the hypothesis function accommodating these multiple features is as follows:\n",
    "\n",
    "$h_\\theta (x) = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\theta_3 x_3 + \\cdots + \\theta_n x_n$\n",
    "\n",
    "In order to develop intuition about this function, we can think about $\\theta_0$ as the basic price of a house, $\\theta_1$ as the price per square meter, $\\theta_2$ as the price per floor, etc. $x_1$ will be the number of square meters in the house, $x_2$ the number of floors, etc.\n",
    "\n",
    "Using the definition of matrix multiplication, our multivariable hypothesis function can be concisely represented as:\n",
    "$\\begin{align*}h_\\theta(x) =\\begin{bmatrix}\\theta_0 \\hspace{2em} \\theta_1 \\hspace{2em} ... \\hspace{2em} \\theta_n\\end{bmatrix}\\begin{bmatrix}x_0 \\newline x_1 \\newline \\vdots \\newline x_n\\end{bmatrix}= \\theta^T x\\end{align*}$\n",
    "\n",
    "### Gradient Descent for Multiple Variables\n",
    "\n",
    "The gradient descent equation itself is generally the same form; we just have to repeat it for our 'n' features and we must treat $x_0=1$:\n",
    "\n",
    "$\\begin{align*} & \\text{repeat until convergence:} \\; \\lbrace \\newline \\; & \\theta_0 := \\theta_0 - \\alpha \\frac{1}{m} \\sum\\limits_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) \\cdot x_0^{(i)}\\newline \\; & \\theta_1 := \\theta_1 - \\alpha \\frac{1}{m} \\sum\\limits_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) \\cdot x_1^{(i)} \\newline \\; & \\theta_2 := \\theta_2 - \\alpha \\frac{1}{m} \\sum\\limits_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) \\cdot x_2^{(i)} \\newline & \\cdots \\newline \\rbrace \\end{align*}$\n",
    "\n",
    "more generally:\n",
    "\n",
    "$\\begin{align*}& \\text{repeat until convergence:} \\; \\lbrace \\newline \\; & \\theta_j := \\theta_j - \\alpha \\frac{1}{m} \\sum\\limits_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) \\cdot x_j^{(i)} \\; & \\text{for j := 0...n}\\newline \\rbrace\\end{align*}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  },
  "language_info": {
   "file_extension": ".m",
   "help_links": [
    {
     "text": "GNU Octave",
     "url": "https://www.gnu.org/software/octave/support.html"
    },
    {
     "text": "Octave Kernel",
     "url": "https://github.com/Calysto/octave_kernel"
    },
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave",
   "version": "5.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
